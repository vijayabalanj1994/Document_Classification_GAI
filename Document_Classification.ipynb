{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21062004-aff8-448a-841a-44aed1093725",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade294e1-72a6-4fec-a5d3-7adaa61254a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppressing warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5bb31a-f096-4116-9ec5-faf2dc561597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import accumulate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer \n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f3ca8-9103-4bb6-86bd-88800b0aa8ce",
   "metadata": {},
   "source": [
    "### Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7bf0184-6698-4fc2-a313-96ba67cc034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(COST,ACC):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(COST, color=color)\n",
    "    ax1.set_xlabel('epoch', color=color)\n",
    "    ax1.set_ylabel('total loss', color=color)\n",
    "    ax1.tick_params(axis='y', color=color)\n",
    "\n",
    "    ax2 = ax1.twix()\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color=color)\n",
    "    ax2.plot(ACC, color=color)\n",
    "    ax2.tick_params(axis='y', color=color)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9d6ae-420e-4f24-b01c-3e9e9cd5733f",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fcd50-d147-4b1c-9b0d-ad0367642481",
   "metadata": {},
   "source": [
    "#### Printing an example document from the AG NEWS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8021ec-0733-4266-a5e4-1ffadce4a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Business\n",
      "Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
     ]
    }
   ],
   "source": [
    "# class labels\n",
    "ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
    "\n",
    "# dataset iterable object from \"torchtext\" library\n",
    "train_iter = iter(AG_NEWS(split='train'))\n",
    "\n",
    "# the 1st example document\n",
    "y, text = next(train_iter)\n",
    "print(f\"Class: {ag_news_label[y]}\\nText: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72711b-c5c8-4372-872c-a51dc3aa8ceb",
   "metadata": {},
   "source": [
    "#### Tokenizing and building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cedbb985-8fda-418c-aff7-eb13502eaac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset iterable object from \"torchtext\" library\n",
    "train_iter = iter(AG_NEWS(split='train'))\n",
    "\n",
    "# The \"basic_english\" tokenizer from \"torchtext\" library\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# a function to get tokenized text for one document at a time\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# building the vocabulary using 'bulid_vocab_from_iterator' function from \"torchtext\" library\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"]) # This index will be returned when OOV token is queried\n",
    "\n",
    "# printing some token indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
